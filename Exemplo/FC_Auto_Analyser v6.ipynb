{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCA2 beta, FCastell Auto Analyser\n",
    "by Fabiano Castello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_Auto_Analyser_Version = \"FCA2 FC Auto Analyser v0.7 beta (jan/20)\"\n",
    "readme_git = \"http://raw.githubusercontent.com/fabianocastello/fca2/master/README.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parâmetros\n",
    "datain    = \".\\data.in\"    #coloque aqui seus arquivos xls ou csv\n",
    "dataout   = \".\\data.out\"   #onde analisador vai gravar os resultados\n",
    "datalog   = \".\\data.log\"   #onde o analisador vai gravar os logs do processamento \n",
    "datatmp   = \".\\data.tmp\"   #arquivos temporários. Será limpo após o processamento\n",
    "\n",
    "max_freq  = 10            #numeros de categorias máximas nos campos texto\n",
    "hist_bins = 10 #qte de bins no histograma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import ExcelFile \n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time, socket\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')  # Use '' for auto, or force e.g. to 'en_US.UTF-8'\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCA2 Starting\n"
     ]
    }
   ],
   "source": [
    "#Criando diretórios se inexistentes\n",
    "print(\"FCA2 Starting\")\n",
    "if not os.path.exists(datatmp):\n",
    "    print(\"diretório \"+datatmp+\" criado\")\n",
    "    os.makedirs(datatmp)\n",
    "if not os.path.exists(dataout):\n",
    "    print(\"diretório \"+dataout+\" criado\")\n",
    "    os.makedirs(dataout)\n",
    "if not os.path.exists(datalog):\n",
    "    print(\"diretório \"+datalog+\" criado\")\n",
    "    os.makedirs(datalog)\n",
    "    \n",
    "if not os.path.exists(datain):\n",
    "    print(\"diretório \"+datain+\" não existe\")\n",
    "    quit()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_to_length(string_to_expand, length):\n",
    "    return (string_to_expand * (int(length/len(string_to_expand))+1))[:length]\n",
    "    \n",
    "def log_start(log_file_open, message):\n",
    "    tmp_computer_name = socket.gethostname()\n",
    "    global log_file ; global log_count; global LogElap; global LogElap_FULL \n",
    "    log_file = open(datalog+\"/\"+log_file_open,\"w+\")\n",
    "    log_count = 1  \n",
    "    now = datetime.now()  \n",
    "    LogElap = time.time()\n",
    "    LogElap_FULL = time.time()\n",
    "    log_file.write(\"**LOG \"+FC_Auto_Analyser_Version+\"** \\n\") \n",
    "    log_file.write(repeat_to_length(\"-\",80) + \"\\n\")\n",
    "    log_file.write(message  + \"\\n\")\n",
    "    log_file.write(repeat_to_length(\"-\",80) + \"\\n\")\n",
    "    log_file.write(os.getcwd() + \"\\n\")\n",
    "    log_file.write(log_file_open + \"\\n\" + \"Running on \" + tmp_computer_name.upper() + \" \\n\")\n",
    "    log_file.write(repeat_to_length(\"-\",80) + \"\\n\")\n",
    "    log_file.write('{:4d}'.format(log_count) + \"  \" + now.strftime(\"%d/%m/%Y %H:%M:%S\") +\n",
    "                  \"     <<<<< Log start >>>>> \\n\\n\")\n",
    "    \n",
    "def log_write(log_message, tela = 0):\n",
    "    global log_count; global LogElap\n",
    "    now = datetime.now()\n",
    "    log_count = log_count + 1\n",
    "    if tela == 1:\n",
    "        print('{:4d}'.format(log_count) + \"  \" + now.strftime(\"%d/%m/%Y %H:%M:%S\") + \n",
    "              \"    \" + log_message + \"\\n\")\n",
    "    log_file.write('{:4d}'.format(log_count) + \"  \" + now.strftime(\"%d/%m/%Y %H:%M:%S\") + \n",
    "              \"     \" + log_message + \"\\n\")\n",
    "\n",
    "    \n",
    "    LogElap = time.time()\n",
    "    \n",
    "def log_close(send_email = False):\n",
    "    global log_count\n",
    "    now = datetime.now()\n",
    "    log_count = log_count + 1\n",
    "    log_file.write(\"\\n\" + '{:4d}'.format(log_count) + \"  \" + now.strftime(\"%d/%m/%Y %H:%M:%S\") +\n",
    "                  \"     <<<<< Log end >>>>> \\n\")\n",
    "    log_file.write(repeat_to_length(\"-\",80) + \"\\n\")\n",
    "    log_file.write(\"Running time total:  \" + convert(time.time() - LogElap_FULL) + \"\\n\")\n",
    "    log_file.write(repeat_to_length(\"-\",80) + \"\\n\")\n",
    "    log_file.write(\"** Get latest version @ github.com/fabianocastello/fca2\\n\")\n",
    "\n",
    "    log_file.close() \n",
    "    return(0)\n",
    "\n",
    "def convert(seconds): \n",
    "    seconds = seconds % (24 * 3600) \n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    return \"%00d:%02d:%02d\" % (hour, minutes, seconds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "global main_log_file\n",
    "WorkOn = 'FCA2_'+datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "main_log_file = WorkOn+\".log\" \n",
    "log_start(main_log_file,\"Análise automática de arquivos de dados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_analysis(file):\n",
    "    \n",
    "    global df,ctmp, ctmp_counts, i, x  #apenas para teste, retirar na versão final\n",
    "\n",
    "    try:\n",
    "        log_write(\"Iniciando análise de \"+file)\n",
    "        \n",
    "        # open the file\n",
    "        if 'csv' in file:\n",
    "            try:\n",
    "                f = open(datain+\"/\"+file)\n",
    "                line = f.readline()\n",
    "                f.close()\n",
    "                semicolon = line.count(\";\")\n",
    "                comma = line.count(\",\")\n",
    "                if semicolon > comma:\n",
    "                    separador = \";\"\n",
    "                else:\n",
    "                    separador = \",\"\n",
    "                log_write(\"Separador de CSV selecionado [\"+separador+\"]\")\n",
    "                df = pd.read_csv(datain+\"/\"+file, encoding ='latin1', engine='python', sep = separador)\n",
    "            except Exception as erro:\n",
    "                log_write(\"Erro \"+str(erro))\n",
    "                log_write(\"Abortando analise \"+file+\"\\n\")\n",
    "                return(-1)\n",
    "        elif 'xls'in file:\n",
    "            try:\n",
    "                df = pd.read_excel(datain+\"/\"+file)\n",
    "            except Exception as erro:\n",
    "                log_write(\"Erro \"+str(erro))\n",
    "                log_write(\"Abortando analise \"+file+\"\\n\")\n",
    "                return(-1)\n",
    "        else:\n",
    "            log_write(\"Erro identificando xls/csv\")\n",
    "            return(-1)\n",
    "    \n",
    "        parse_file = open(dataout+\"\\\\\"+file+'.txt',\"w+\")\n",
    "        parse_file.write(FC_Auto_Analyser_Version+\"\\n\") \n",
    "        parse_file.write(\"Arquivo \"+ file +\"\\n\" ) \n",
    "        parse_file.write(repeat_to_length(\"-\",80) + \"\\n\")\n",
    "        \n",
    "        ## MORFOLOGIA\n",
    "        reg_total = df.shape[0]\n",
    "        parse_file.write(\"### MORFOLOGIA de \"+ file +\"\\n\\n\" ) \n",
    "        parse_file.write('{:4d}'.format(reg_total)+\" registros e \"+\n",
    "                         str(df.shape[1])+\" campos, sendo: \"+\"\\n\\n\" ) \n",
    "        log_write(str(reg_total)+\" registros e \"+ str(df.shape[1])+\" campos\" )\n",
    "\n",
    "        xext = '' ;  xqte = 0\n",
    "        for x in df.columns:\n",
    "            if df[x].dtype == np.object:\n",
    "                xext = xext + sep(xqte) +x  ; xqte += 1 \n",
    "        parse_file.write('{:4d}'.format(xqte)+\" campos tipo texto\"+\"\\n\" ) \n",
    "        if xqte != 0: parse_file.write(\"     [\"+xext+\"]\\n\" ) \n",
    "        log_write(str(xqte)+\" campos tipo texto\" )\n",
    "\n",
    "        xqte_corr = 0\n",
    "        xext = '' ;  xqte = 0\n",
    "        for x in df.columns:\n",
    "            if df[x].dtype == np.int64:\n",
    "                xext = xext + sep(xqte) +x  ; xqte += 1 \n",
    "        parse_file.write('{:4d}'.format(xqte)+\" campos tipo numérico (inteiro)\"+\"\\n\" ) \n",
    "        if xqte != 0: parse_file.write(\"     [\"+xext+\"]\\n\" ) \n",
    "        log_write(str(xqte)+\" campos tipo numérico (inteiro)\" )\n",
    "        xqte_corr += xqte\n",
    "\n",
    "        xext = '' ;  xqte = 0\n",
    "        for x in df.columns:\n",
    "            if df[x].dtype == np.float64:\n",
    "                xext = xext + sep(xqte) +x  ; xqte += 1 \n",
    "        parse_file.write('{:4d}'.format(xqte)+\" campos tipo numério (decimal)\"+\"\\n\" ) \n",
    "        if xqte != 0: parse_file.write(\"     [\"+xext+\"]\\n\" ) \n",
    "        log_write(str(xqte)+\" campos tipo numérico (decimal)\" )\n",
    "        xqte_corr += xqte\n",
    "\n",
    "        xext = '' ;  xqte = 0\n",
    "        for x in df.columns:\n",
    "            if not (df[x].dtype == np.object or df[x].dtype == np.float64 or df[x].dtype == np.int64):\n",
    "                xext = xext + sep(xqte) +x  ; xqte += 1 \n",
    "        parse_file.write('{:4d}'.format(xqte)+\" campos de outros tipos\"+\"\\n\" ) \n",
    "        if xqte != 0: parse_file.write(\"     [\"+xext+\"]\\n\" ) \n",
    "        log_write(str(xqte)+\" campos de outros tipos\" )\n",
    "    \n",
    "        ## CAMPOS TEXTO\n",
    "        parse_file.write(repeat_to_length(\"-\",80) + \"\\n\")\n",
    "        parse_file.write(\"### ANÁLISE DOS CAMPOS TIPO TEXTO de \"+ file +\"\\n\\n\" ) \n",
    "        for x in df.columns:\n",
    "            if df[x].dtype == np.object:\n",
    "                xext = xext + sep(xqte) +x  ; xqte += 1 \n",
    "                parse_file.write(str(xqte)+\") ** \"+ x + \" [\"+x.upper()+\"] \\n\\n\") \n",
    "                ctmp = df[x]\n",
    "                ctmp_counts = ctmp.value_counts()\n",
    "                ctmp_total = reg_total\n",
    "                nulos = ctmp.isna().sum() \n",
    "                ctmp = ctmp.dropna()\n",
    "                parse_file.write(repeat_to_length(\" \",6)+\"registros:  \"+'{:n}'.format(ctmp_total) + \" \\n\") \n",
    "                parse_file.write(repeat_to_length(\" \",6)+\"missing:    \"+'{:n}'.format(nulos) + \" \\n\") \n",
    "                parse_file.write(repeat_to_length(\" \",6)+\"válidos:    \"+'{:n}'.format(ctmp_total-nulos) + \" \\n\") \n",
    "                ctmp.drop_duplicates(keep='first', inplace = True) \n",
    "                ctmp_final = ctmp.shape[0]\n",
    "                parse_file.write(repeat_to_length(\" \",6)+\"duplicados: \"+'{:n}'.format(ctmp_total-nulos-ctmp_final) + \" \\n\") \n",
    "                parse_file.write(repeat_to_length(\" \",6)+\"categorias: \"+'{:n}'.format(ctmp_final) + \" \\n\\n\")\n",
    "\n",
    "                if (ctmp_total-ctmp_final) == 0:\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"<<<categorias = registros, zero duplicados>>>\\n\")\n",
    "                else:\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Freqs  [f.abs] [ f.rel%] [f.acc%] categorias (max = \"+'{:n}'.format(max_freq) +\")\\n\")\n",
    "                    freq     = 0\n",
    "                    freq_acc = 0\n",
    "                    for key, value in ctmp_counts.iteritems():\n",
    "                        if freq <= max_freq:\n",
    "                            freq += 1\n",
    "                            freq_acc = freq_acc + (value/ctmp_total)\n",
    "                            parse_file.write(repeat_to_length(\" \",6)+\"[\"+'{:>12,.0f}'.format(value)+\n",
    "                                             \"] [ \" +'{:>5,.1f}'.format(value/ctmp_total*100) +\"%] [\"  \n",
    "                                                    +'{:>5,.1f}'.format(freq_acc*100) +\"%] \"  \n",
    "                                             +str(key)+\" \\n\")         \n",
    "                            \n",
    "                                                \n",
    "                parse_file.write(\" \\n\\n\") \n",
    "    \n",
    "        ## CAMPOS NUMÉRICOS (INTEIROS e DECIMAIS)\n",
    "        parse_file.write(repeat_to_length(\"-\",80) + \"\\n\")\n",
    "        parse_file.write(\"### ANÁLISE DOS CAMPOS NUMÉRICOS (INTEIROS E DECIMAIS) de \"+ file +\"\\n\\n\" ) \n",
    "        for x in df.columns:\n",
    "            if df[x].dtype == np.int64 or df[x].dtype == np.float64:\n",
    "                xqte += 1 \n",
    "                parse_file.write(str(xqte)+\") ** \"+ x + \" [\"+x.upper()+\"] \")\n",
    "    \n",
    "                if df[x].sum() == 0:   \n",
    "                    parse_file.write(\"\\n\\n\"+repeat_to_length(\" \",6)+\"<<<Todos os valores zerados>>>\\n\\n\") \n",
    "                else:\n",
    "                    if df[x].dtype == np.int64:\n",
    "                        parse_file.write(\"[INTEIRO]\") \n",
    "                    else:\n",
    "                        parse_file.write(\"[DECIMAL]\")\n",
    "                        \n",
    "                    parse_file.write(\"\\n\\n\") \n",
    "                    ctmp = df[x]\n",
    "                    nulos = ctmp.isna().sum() \n",
    "                    ctmpZ = ctmp[ctmp != 0]\n",
    "                    ctmpZ = ctmpZ.dropna()\n",
    "                    ctmpZEXC = ctmp[ctmp == 0]\n",
    "                    zerados = ctmpZEXC.shape[0]\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Registros:    \"+'{:>15,.0f}'.format(reg_total) + \"\\n\")\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Missing:      \"+'{:>15,.0f}'.format(nulos) + \"\\n\")\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Válidos:      \"+'{:>15,.0f}'.format(reg_total-nulos) + \"\\n\")\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Zerados:      \"+'{:>15,.0f}'.format(zerados) + \"\\n\\n\")\n",
    "\n",
    "                    parse_file.write(repeat_to_length(\" \",31)+\"[Válidos]\")\n",
    "                    if zerados != 0: parse_file.write(repeat_to_length(\" \",2)+\"[Válidos Exc. Zero]\"+\"\\n\")\n",
    "                    else:            parse_file.write(\"\\n\")\n",
    "                                         \n",
    "                                     \n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Registros:    \"+'{:>15,.0f}'.format(reg_total-nulos))\n",
    "                    if zerados != 0: parse_file.write(\"      \"+'{:>15,.0f}'.format(ctmpZ.shape[0])+\"\\n\" )\n",
    "                    else:            parse_file.write(\"\\n\")\n",
    "                                     \n",
    "\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Soma:         \"+'{:>20,.4f}'.format(ctmp.sum()))\n",
    "                    if zerados != 0: parse_file.write(\" \"+'{:>20,.4f}'.format(ctmpZ.sum())+\"\\n\" )\n",
    "                    else:            parse_file.write(\"\\n\")\n",
    "                    \n",
    "\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Média:        \"+'{:>20,.4f}'.format(ctmp.describe()[1]))\n",
    "                    if zerados != 0: parse_file.write(\" \"+'{:>20,.4f}'.format(ctmpZ.describe()[1])+\"\\n\" )\n",
    "                    else:            parse_file.write(\"\\n\")\n",
    "                    \n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Desvio:       \"+'{:>20,.4f}'.format(ctmp.describe()[2]))\n",
    "                    if zerados != 0: parse_file.write(\" \"+'{:>20,.4f}'.format(ctmpZ.describe()[2])+\"\\n\" )\n",
    "                    else:            parse_file.write(\"\\n\")\n",
    "\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Mínimo:       \"+'{:>20,.4f}'.format(ctmp.describe()[3]))\n",
    "                    if zerados != 0: parse_file.write(\" \"+'{:>20,.4f}'.format(ctmpZ.describe()[3])+\"\\n\" )\n",
    "                    else:            parse_file.write(\"\\n\")\n",
    "\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Máximo:       \"+'{:>20,.4f}'.format(ctmp.describe()[7]))\n",
    "                    if zerados != 0: parse_file.write(\" \"+'{:>20,.4f}'.format(ctmpZ.describe()[7])+\"\\n\" )\n",
    "                    else:            parse_file.write(\"\\n\")\n",
    "\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"Amplitude:    \"+'{:>20,.4f}'.format(ctmp.describe()[7]-\n",
    "                                                            ctmp.describe()[3]))\n",
    "                    if zerados != 0: parse_file.write(\" \"+'{:>20,.4f}'.format(ctmpZ.describe()[7]-\n",
    "                                                            ctmpZ.describe()[3])+\"\\n\" )\n",
    "                    else:            parse_file.write(\"\\n\")\n",
    "\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"25%:          \"+'{:>20,.4f}'.format(ctmp.describe()[4]))\n",
    "                    if zerados != 0: parse_file.write(\" \"+'{:>20,.4f}'.format(ctmpZ.describe()[4])+\"\\n\" )\n",
    "                    else:            parse_file.write(\"\\n\")\n",
    "\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"50%:          \"+'{:>20,.4f}'.format(ctmp.describe()[5]))\n",
    "                    if zerados != 0: parse_file.write(\" \"+'{:>20,.4f}'.format(ctmpZ.describe()[5])+\"\\n\" )\n",
    "                    else:            parse_file.write(\"\\n\")\n",
    "\n",
    "                    parse_file.write(repeat_to_length(\" \",6)+\"75%:          \"+'{:>20,.4f}'.format(ctmp.describe()[6]))\n",
    "                    if zerados != 0: parse_file.write(\" \"+'{:>20,.4f}'.format(ctmpZ.describe()[6])+\"\\n\" )\n",
    "                    else:            parse_file.write(\"\\n\")\n",
    "\n",
    "\n",
    "                    grf = df[x].dropna()    \n",
    "                    grfINFO = grf.describe()\n",
    "                    max_height = (np.histogram(grf, bins=hist_bins)[0].max())\n",
    "                    max_lenght = (grfINFO[7]- grfINFO[3])\n",
    "                    sns.set_style(\"whitegrid\")\n",
    "                    plt.figure(figsize=(11.7, 8.27))\n",
    "                    plt.xlim(grfINFO[3].round(0), grfINFO[7].round(0))\n",
    "                    plt.ylim(0, max_height*1.1)\n",
    "                    \n",
    "                    plt.text(0.03*max_lenght,-0.09*max_height,\n",
    "                             FC_Auto_Analyser_Version+'\\n'+'http://github.com/fabianocastello/fca2',\n",
    "                             fontsize=10, ha='left')\n",
    "                    \n",
    "                    sns_plot = sns.distplot(grf, bins=hist_bins, kde=False, color=\"purple\", \n",
    "                                 axlabel=False, rug=True)\n",
    "                    sns_plot = sns_plot.set_title(\"histograma de [\"+grf.name+\"]\", {'size': '18'})\n",
    "                    fig = sns_plot.get_figure().savefig(dataout+\"\\\\\"+file+' HIST '+grf.name+'.png')  #pdf: trocar sufixo\n",
    "                    plt.close()\n",
    "                    log_write(\"Histograma gravado \"+file+' HIST '+grf.name+'.png')\n",
    "\n",
    "                        \n",
    "                        \n",
    "                    parse_file.write(\" \\n\\n\") \n",
    "                        \n",
    "        parse_file.write(repeat_to_length(\"-\",80) + \"\\n\")\n",
    "        \n",
    "        ## CORRELAÇÃO ENTRE VARIÁVEIS NUMÉRICAS\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        plt.figure(figsize=(11.7, 8.27))\n",
    "        plt.text(0.3, xqte_corr,\n",
    "                 FC_Auto_Analyser_Version+'\\n'+'http://github.com/fabianocastello/fca2',\n",
    "                 fontsize=10, ha='left')\n",
    "        sns_corr = sns.heatmap(df.corr())\n",
    "        sns_corr = sns_corr.set_title(\"Correlação entre variáveis\", {'size': '18'})\n",
    "        sns_corr.get_figure().savefig(dataout+\"\\\\\"+file+' CORR.png')\n",
    "        plt.close()\n",
    "\n",
    "        ## CLOSING\n",
    "        try:\n",
    "            r = requests.get(readme_git)\n",
    "            version_git = r.text[2:43].strip()\n",
    "            if version_git != FC_Auto_Analyser_Version:\n",
    "                parse_file.write(\"** ATENÇÃO! nova versão disponível!\\n\")\n",
    "                parse_file.write(\"  Você está usando: \"+FC_Auto_Analyser_Version + \"\\n\")\n",
    "                parse_file.write(\"  e a nova é:       \"+version_git+ \"\\n\")            \n",
    "                parse_file.write(\"  visite github.com/fabianocastello/fca2 para baixar a nova versão \\n\")            \n",
    "                parse_file.write(repeat_to_length(\"-\",80) + \"\\n\")            \n",
    "            parse_file.write(\"READ.ME de \"+readme_git+\"\\n\\n\")\n",
    "            parse_file.write(r.text)\n",
    "        except Exception as erro:\n",
    "            parse_file.write(\"** Não foi possível recuperar README do github!\\n\")\n",
    "            parse_file.write(\"Erro \"+str(erro)+\"\\n\")\n",
    "            parse_file.write(\"** Leia o README no endereço\\n\")\n",
    "            parse_file.write(\"   github.com/fabianocastello/fca2\\n\")\n",
    "            \n",
    "            parse_file.write(repeat_to_length(\"-\",80) + \"\\n\")            \n",
    "\n",
    "        parse_file.write(repeat_to_length(\"-\",80) + \"\\n\")  \n",
    "        parse_file.write(file+\" ending. Bye!\\n\")\n",
    "        parse_file.close() \n",
    "        log_write(\"Análise finalizada de \"+file+ \"\\n\")\n",
    "        return(0)\n",
    "\n",
    "    except Exception as erro:\n",
    "        parse_file.write(\"\\n\\n Erro Geral: \"+str(erro) + \"\\n\\n\") \n",
    "        parse_file.close() \n",
    "        log_write(\"Erro Geral: \"+str(erro))\n",
    "        log_write(\"Abortando analise \"+file+\"\\n\")\n",
    "        return(-2)\n",
    "        \n",
    "def sep(ser):\n",
    "    if ser > 0: return(\" | \")\n",
    "    return(\"\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "files = os.listdir(datain)\n",
    "dfx = [i for i in files if 'XLS' in i.upper()] \n",
    "dfc = [i for i in files if 'CSV' in i.upper()] \n",
    "filesToWorkOn = dfx + dfc\n",
    "log_write(\"Procurando arquivos em \"+datain)\n",
    "log_write(\"Arquivos tipos xls \"+'{:3d}'.format(len(dfx)))\n",
    "log_write(\"Arquivos tipos csv \"+'{:3d}'.format(len(dfc)))\n",
    "log_write(\"Total              \"+'{:3d}'.format(len(filesToWorkOn))+\"\\n\")\n",
    "del dfx, dfc, files\n",
    "filesToWorkOn = sorted(filesToWorkOn) \n",
    "all_files_to_log =\"Arquivos para analisar:\"+ \"\\n\" + repeat_to_length(\" \",30)\n",
    "for name in filesToWorkOn:\n",
    "    all_files_to_log = all_files_to_log + name + \"\\n\" + repeat_to_length(\" \",30)\n",
    "\n",
    "log_write(all_files_to_log)\n",
    "\n",
    "for name in filesToWorkOn:\n",
    "    csv_analysis(name)\n",
    "\n",
    "log_close()\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
